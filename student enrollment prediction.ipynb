{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "\n",
        "# 1. Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Student_performance_data _.csv')\n",
        "\n",
        "# 2. Create the new target variables\n",
        "# EnrollmentLikelihood: 1 if GPA >= 3.0, else 0\n",
        "data['EnrollmentLikelihood'] = (data['GPA'] >= 3.0).astype(int)\n",
        "\n",
        "# NeedForSupport: 1 if GPA < 2.5 or Absences > 5, else 0\n",
        "data['NeedForSupport'] = ((data['GPA'] < 2.5) | (data['Absences'] > 5)).astype(int)\n",
        "\n",
        "# 3. Preprocess the data\n",
        "\n",
        "# Step 1: Handle missing values (imputation strategy)\n",
        "imputer = SimpleImputer(strategy='mean')  # Impute missing numerical values with the mean\n",
        "data[['Age', 'StudyTimeWeekly', 'Absences']] = imputer.fit_transform(data[['Age', 'StudyTimeWeekly', 'Absences']])\n",
        "\n",
        "# Step 2: Encode categorical features using LabelEncoder\n",
        "categorical_features = ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring',\n",
        "                        'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'Volunteering']\n",
        "\n",
        "label_encoders = {}\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    data[feature] = le.fit_transform(data[feature])\n",
        "    label_encoders[feature] = le  # Store the label encoder for each feature\n",
        "\n",
        "# Step 3: Feature Scaling (optional)\n",
        "scaler = StandardScaler()\n",
        "numerical_features = ['Age', 'StudyTimeWeekly', 'Absences']\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
        "\n",
        "# 4. Split the data into training and testing sets (80% for training, 20% for testing)\n",
        "X = data.drop(columns=['StudentID', 'GPA', 'GradeClass', 'EnrollmentLikelihood', 'NeedForSupport'])  # Features\n",
        "y = data[['EnrollmentLikelihood', 'NeedForSupport']]  # Multi-output target variable\n",
        "\n",
        "# Split data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train the RandomForestClassifier model for multi-output classification\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate the model's performance using accuracy_score and classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance for EnrollmentLikelihood\n",
        "print(\"Enrollment Likelihood Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test['EnrollmentLikelihood'], y_pred[:, 0])}\")\n",
        "print(classification_report(y_test['EnrollmentLikelihood'], y_pred[:, 0]))\n",
        "\n",
        "# Evaluate performance for NeedForSupport\n",
        "print(\"Need for Support Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test['NeedForSupport'], y_pred[:, 1])}\")\n",
        "print(classification_report(y_test['NeedForSupport'], y_pred[:, 1]))\n",
        "\n",
        "# 7. Optionally, save the trained model to a file\n",
        "joblib.dump(model, 'student_performance_model.pkl')\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(\"Model and preprocessing tools have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJFrKALxvWW4",
        "outputId": "e1586da2-f0ef-4c19-f82b-4434e9c9c0ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enrollment Likelihood Model Evaluation:\n",
            "Accuracy: 0.9331941544885177\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       414\n",
            "           1       0.79      0.69      0.74        65\n",
            "\n",
            "    accuracy                           0.93       479\n",
            "   macro avg       0.87      0.83      0.85       479\n",
            "weighted avg       0.93      0.93      0.93       479\n",
            "\n",
            "Need for Support Model Evaluation:\n",
            "Accuracy: 0.9874739039665971\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        90\n",
            "           1       1.00      0.98      0.99       389\n",
            "\n",
            "    accuracy                           0.99       479\n",
            "   macro avg       0.97      0.99      0.98       479\n",
            "weighted avg       0.99      0.99      0.99       479\n",
            "\n",
            "Model and preprocessing tools have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load the trained model and preprocessing tools\n",
        "model = joblib.load('student_performance_model.pkl')\n",
        "label_encoders = joblib.load('label_encoders.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# 2. Sample data for predictions\n",
        "new_students_data = pd.DataFrame([\n",
        "    {'Age': 22, 'Gender': 'Male', 'Ethnicity': 'Hispanic', 'ParentalEducation': 'High School',\n",
        "     'StudyTimeWeekly': 10, 'Absences': 2, 'Tutoring': 'No', 'ParentalSupport': 'High',\n",
        "     'Extracurricular': 'Yes', 'Sports': 'Yes', 'Music': 'No', 'Volunteering': 'No'},\n",
        "\n",
        "    {'Age': 19, 'Gender': 'Female', 'Ethnicity': 'White', 'ParentalEducation': \"Bachelor's Degree\",\n",
        "     'StudyTimeWeekly': 15, 'Absences': 5, 'Tutoring': 'Yes', 'ParentalSupport': 'Medium',\n",
        "     'Extracurricular': 'No', 'Sports': 'No', 'Music': 'Yes', 'Volunteering': 'Yes'},\n",
        "\n",
        "    {'Age': 20, 'Gender': 'Male', 'Ethnicity': 'African American', 'ParentalEducation': 'Some College',\n",
        "     'StudyTimeWeekly': 8, 'Absences': 7, 'Tutoring': 'No', 'ParentalSupport': 'Low',\n",
        "     'Extracurricular': 'Yes', 'Sports': 'No', 'Music': 'No', 'Volunteering': 'Yes'},\n",
        "])\n",
        "\n",
        "# 3. Preprocess the new student's data similarly to the training data\n",
        "# 3.1 Handle missing values (if any) - using SimpleImputer\n",
        "categorical_features = ['Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring',\n",
        "                        'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'Volunteering']\n",
        "numerical_features = ['Age', 'StudyTimeWeekly', 'Absences']\n",
        "\n",
        "# Create imputer with mean strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "new_students_data[numerical_features] = imputer.fit_transform(new_students_data[numerical_features])\n",
        "\n",
        "# 3.2 Encode categorical features using LabelEncoder\n",
        "for feature in categorical_features:\n",
        "    # Check if the new value is in the label encoder's classes\n",
        "    # If not, add it to the label encoder's classes and re-fit\n",
        "    if not all(value in label_encoders[feature].classes_ for value in new_students_data[feature].unique()):\n",
        "        # Convert existing classes to string type\n",
        "        label_encoders[feature].classes_ = label_encoders[feature].classes_.astype(str)\n",
        "\n",
        "        # Get new unique values not present in existing classes using numpy\n",
        "        new_values = np.setdiff1d(new_students_data[feature].unique(), label_encoders[feature].classes_)\n",
        "\n",
        "        # Extend the classes_ attribute with new values, maintaining dtype using numpy\n",
        "        label_encoders[feature].classes_ = np.concatenate([label_encoders[feature].classes_, new_values])\n",
        "\n",
        "    new_students_data[feature] = label_encoders[feature].transform(new_students_data[feature])\n",
        "\n",
        "# 3.3 Scale numerical features using StandardScaler\n",
        "new_students_data[numerical_features] = scaler.transform(new_students_data[numerical_features])\n",
        "\n",
        "# 4. Make predictions\n",
        "predictions = model.predict(new_students_data)\n",
        "\n",
        "# 5. Print the predictions\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"Predictions for student {i + 1}:\")\n",
        "    print(f\"  Enrollment Likelihood: {prediction[0]}\")\n",
        "    print(f\"  Need for Support: {prediction[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlQ5ZaKj2i9G",
        "outputId": "904151ec-bf8f-4601-e685-da97cce8fb7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for student 1:\n",
            "  Enrollment Likelihood: 1\n",
            "  Need for Support: 0\n",
            "Predictions for student 2:\n",
            "  Enrollment Likelihood: 1\n",
            "  Need for Support: 0\n",
            "Predictions for student 3:\n",
            "  Enrollment Likelihood: 0\n",
            "  Need for Support: 1\n"
          ]
        }
      ]
    }
  ]
}
